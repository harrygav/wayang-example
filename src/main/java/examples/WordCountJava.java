package examples;

import org.apache.wayang.api.JavaPlanBuilder;
import org.apache.wayang.basic.data.Tuple2;
import org.apache.wayang.core.api.Configuration;
import org.apache.wayang.core.api.WayangContext;
import org.apache.wayang.core.optimizer.cardinality.DefaultCardinalityEstimator;
import org.apache.wayang.java.Java;
import org.apache.wayang.spark.Spark;

import java.net.URL;
import java.nio.file.Paths;
import java.util.Collection;
import java.util.Arrays;

public class WordCountJava {

    public static void main(String[] args) {

        // Settings
        String filename = "sample.txt";

        try {

            URL resource = WordCountJava.class.getResource("/" + filename);
            String inputUrl = "file:" + Paths.get(resource.toURI()).toFile();


            // Get a plan builder.
            WayangContext wayangContext = new WayangContext(new Configuration())
                    .withPlugin(Java.basicPlugin())
                    .withPlugin(Spark.basicPlugin());
            JavaPlanBuilder planBuilder = new JavaPlanBuilder(wayangContext)
                    .withJobName(String.format("WordCount (%s)", inputUrl))
                    .withUdfJarOf(WordCountJava.class);

            // Start building the WayangPlan.
            Collection<Tuple2<String, Integer>> wordcounts = planBuilder
                    // Read the text file.
                    .readTextFile(inputUrl).withName("Load file")

                    // Split each line by non-word characters.
                    .flatMap(line -> Arrays.asList(line.split("\\W+")))
                    .withSelectivity(10, 100, 0.9)
                    .withName("Split words")

                    // Filter empty tokens.
                    .filter(token -> !token.isEmpty())
                    .withSelectivity(0.99, 0.99, 0.99)
                    .withName("Filter empty words")

                    // Attach counter to each word.
                    .map(word -> new Tuple2<>(word.toLowerCase(), 1)).withName("To lower case, add counter")

                    // Sum up counters for every word.
                    .reduceByKey(
                            Tuple2::getField0,
                            (t1, t2) -> new Tuple2<>(t1.getField0(), t1.getField1() + t2.getField1())
                    )
                    .withCardinalityEstimator(new DefaultCardinalityEstimator(0.9, 1, false, in -> Math.round(0.01 * in[0])))
                    .withName("Add counters")

                    // Execute the plan and collect the results.
                    .collect();

            System.out.println(wordcounts);
        } catch (Exception e) {

            System.out.println("Path does not exist");

        }
    }
}